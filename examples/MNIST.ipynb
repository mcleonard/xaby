{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on MNIST with XABY\n",
    "\n",
    "This notebook demonstrates how to train a fully connected network (not convolutional!) on MNIST with the XABY framework. I'll also compare it to PyTorch so you can see the different APIs and performances.\n",
    "\n",
    "I'm going to use torchvision to load in the MNIST data, because it's super great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mat/miniconda3/envs/xaby/lib/python3.6/site-packages/jax/lib/xla_bridge.py:120: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import xaby as xb\n",
    "import xaby.nn as xn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "mnist_train = datasets.MNIST(\"~/.pytorch\", train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.MNIST(\"~/.pytorch\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=128, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Models\n",
    "\n",
    "First up, I'll define two models with the same architecture. One with XABY, the other with PyTorch. \n",
    "\n",
    "XABY models are defined as a sequence of operations. When a model is defined, it is compiled behind the scenes into a single function. You call the function with some input like `inputs >> model`. I had a lot of fun messing with Python operators. My intention of doing it this way is if you chain a lot of functions, the last function called is the first function you read. I'm using the `>>` operator so you can write the chain of functions in the order they are called.\n",
    "\n",
    "You can define the PyTorch model with `torch.nn.Sequential`, but sublassing from `torch.nn.Module` is the preferred method, so I'll do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XABY model ##\n",
    "xaby_model = xb.flatten(axis=0) >> xn.linear(784, 256) >> xn.relu \\\n",
    "          >> xn.linear(256, 10) >> xn.log_softmax(axis=0)\n",
    "\n",
    "## PyTorch Model ##\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "torch_model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run data through the models!\n",
    "\n",
    "Just a small example of using XABY models for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[flatten(axis=0), linear(784, 256)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xb.flatten(axis=0) >> xn.linear(784, 256)\n",
    "model.funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XABY device: CPU_0\n"
     ]
    }
   ],
   "source": [
    "# Get data from the image loader\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Convert PyTorch Tensor to a XABY Tensor\n",
    "inputs = xb.array(images)\n",
    "\n",
    "# Thanks to JAX, XABY tensors are automatically on the GPU (if one is available)\n",
    "print(f\"XABY device: {inputs.device_buffer.device()}\")\n",
    "\n",
    "# # Call the model in a fun manner\n",
    "log_p = xb.pack(inputs) >> xaby_model\n",
    "\n",
    "# Normal function call... boring....\n",
    "log_p = xaby_model([inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should also note you can run XABY tensors through operations without creating models. This returns another tensor. If you start the sequence with an operation, it'll create a model. If you start with a tensor, it'll run through the operations and return a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArrayList:\n",
       "DeviceArray([[-5.8770366, -5.066442 , -4.79475  , ..., -4.3894086,\n",
       "              -4.1645303, -4.122983 ],\n",
       "             [-6.409501 , -4.884922 , -5.16696  , ..., -5.132159 ,\n",
       "              -5.6830263, -4.7853403],\n",
       "             [-5.9576216, -4.6665373, -5.8496127, ..., -5.3701186,\n",
       "              -5.351577 , -4.1037207],\n",
       "             ...,\n",
       "             [-4.988286 , -5.032884 , -4.3581915, ..., -4.2848635,\n",
       "              -5.451784 , -5.26558  ],\n",
       "             [-5.471991 , -5.1795793, -5.338534 , ..., -6.9221115,\n",
       "              -4.769789 , -4.616245 ],\n",
       "             [-5.0198245, -4.761364 , -4.662118 , ..., -5.128957 ,\n",
       "              -5.5828953, -5.210172 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.pack(inputs) >> xb.flatten(axis=0) >> xn.linear(784, 10) >> xn.log_softmax(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing XABY and PyTorch\n",
    "\n",
    "Below I'll test how long it takes for inference with these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564 µs ± 73.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# First on CPU\n",
    "torch_model = torch_model.requires_grad_(False)\n",
    "torch_model.to(\"cpu\")\n",
    "images = images.to(\"cpu\")\n",
    "\n",
    "%timeit -n 1000 torch_model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now on GPU\n",
    "torch_model.to(\"cuda\")\n",
    "images = images.to(\"cuda\")\n",
    "\n",
    "%timeit -n 1000 torch_model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584 µs ± 39.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Now the XABY model, runs on GPU!\n",
    "inputs = xb.pack(xb.array(images))\n",
    "\n",
    "%timeit -n 1000 inputs >> xaby_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XABY is slightly slower than PyTorch on the GPU. This might be due to JAX being slower or it's possible I can do some more optimization in XABY.\n",
    "\n",
    "Either way, time to train the models. First up, XABY. I'll use simple stochastic gradient descent for both. The output of the models is log-softmax, so I'll use the negative log-likelihood loss.\n",
    "\n",
    "In XABY, we create a `backprop` function that takes the input and targets, then returns the loss and gradients. When only evaluating, such as in validation, you can get the loss directly:\n",
    "```python\n",
    "loss = inputs >> model >> nlloss << targets\n",
    "```\n",
    "\n",
    "We also create an `update` function that updates a model given gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.316  Test loss: 4.316  Test acc.: 0.687  Images/sec: 5472.408\n",
      "Train loss: 3.950  Test loss: 3.903  Test acc.: 0.787  Images/sec: 8614.372\n",
      "Train loss: 3.702  Test loss: 3.639  Test acc.: 0.824  Images/sec: 8733.214\n",
      "Train loss: 3.546  Test loss: 3.490  Test acc.: 0.844  Images/sec: 8688.598\n"
     ]
    }
   ],
   "source": [
    "### Define a fresh model, in two lines for readability\n",
    "model = xb.flatten(axis=0) >> xn.linear(784, 256) >> xn.relu \\\n",
    "                           >> xn.linear(256, 10) >> xn.log_softmax(axis=0)\n",
    "\n",
    "# loss function\n",
    "loss = xb.nn.nll_loss(model)\n",
    "\n",
    "# Update function\n",
    "update = xb.optim.sgd(lr=0.003)\n",
    "\n",
    "step = 0\n",
    "start = time.time()\n",
    "for images, labels in train_loader:\n",
    "    step += 1\n",
    "    \n",
    "    # Wrap up our input data\n",
    "    inputs = xb.pack(xb.array(images), xb.array(labels))\n",
    "    \n",
    "    # Get the gradients. loss is just a function that accepts two arrays. It returns the mean loss\n",
    "    # for the batch and the gradients for the model parameters\n",
    "    train_loss, grads = inputs >> loss\n",
    "    \n",
    "    # Then, update the model with the gradients\n",
    "    update(model, grads)\n",
    "    \n",
    "    if step % print_every == 0:\n",
    "        stop = time.time()\n",
    "        test_losses = []\n",
    "        test_accuracy = []\n",
    "        \n",
    "        for images, labels in test_loader:\n",
    "            inputs = xb.pack(xb.array(images), xb.array(labels))\n",
    "            \n",
    "            log_p, = model([inputs[0]])\n",
    "            pred_label = xb.jnp.argmax(log_p, axis=1)\n",
    "            test_accuracy.append((inputs[1] == pred_label).mean())\n",
    "            \n",
    "            test_loss, _ = inputs >> loss\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "        print(f\"Train loss: {train_loss:.3f}  \"\n",
    "              f\"Test loss: {sum(test_losses)/len(test_losses):.3f}  \"\n",
    "              f\"Test acc.: {sum(test_accuracy)/len(test_accuracy):.3f}  \"\n",
    "              f\"Images/sec: {print_every*batch_size/(stop - start):.3f}\")\n",
    "        start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.756  Test loss: 1.758  Test accuracy: 0.692  Images/sec: 7621.719\n",
      "Train loss: 1.287  Test loss: 1.292  Test accuracy: 0.784  Images/sec: 8843.463\n",
      "Train loss: 1.085  Test loss: 0.986  Test accuracy: 0.822  Images/sec: 8941.259\n",
      "Train loss: 0.914  Test loss: 0.802  Test accuracy: 0.840  Images/sec: 8812.108\n"
     ]
    }
   ],
   "source": [
    "# Start with a fresh model\n",
    "torch_model = torch.nn.Sequential(\n",
    "                    torch.nn.Flatten(),\n",
    "                    torch.nn.Linear(784, 256),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(256, 10),\n",
    "                    torch.nn.LogSoftmax(1))\n",
    "torch_model.to(\"cpu\")\n",
    "optimizer = torch.optim.SGD(torch_model.parameters(), lr=0.003)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "step = 0\n",
    "start = time.time()\n",
    "for images, labels in train_loader:\n",
    "    step += 1\n",
    "    \n",
    "    inputs, targets = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    log_p = torch_model(inputs)\n",
    "    loss = criterion(log_p, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss = loss.item()\n",
    "    \n",
    "    if step % print_every == 0:\n",
    "        stop = time.time()\n",
    "        test_losses = []\n",
    "        test_accuracy = []\n",
    "        for images, labels in test_loader:\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "                log_p = torch_model(inputs)\n",
    "                loss = criterion(log_p, targets)\n",
    "                accuracy = (log_p.argmax(axis=1) == targets).sum()/float(len(images))\n",
    "            \n",
    "            test_losses.append(loss.item())\n",
    "            test_accuracy.append(accuracy.item())\n",
    "            \n",
    "        print(f\"Train loss: {train_loss:.3f}  \"\n",
    "              f\"Test loss: {sum(test_losses)/len(test_losses):.3f}  \"\n",
    "              f\"Test accuracy: {sum(test_accuracy)/len(test_accuracy):.3f}  \"\n",
    "              f\"Images/sec: {print_every*batch_size/(stop - start):.3f}\")\n",
    "        start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
